# 使用LLM根据基于归纳编码生成适用于大纲category的编码本的提示语。

我现在在做一个定性编码分析工作，希望你帮我做一个对编码本优化的工作。

一、 目标 (Objective)

将基于开放式编码（Inductive Coding）生成的初步编码本，重构为一个结构清晰、逻辑严谨、高度可操作的演绎编码本（Deductive Codebook）。最终的编码本将具备明确的层级结构，且各编码之间意义互斥、无重叠，旨在为后续的编码分析工作提供统一、可靠、高效的分析工具。

二、现有编码本结构与内容

1. code name，编码名称
2. definition，编码概念定义
3. theme，基于访谈问题的初步主题提取，该编码所属的主题
4. source_question，基于什么访谈问题进行编码的
5. frequency_in_qestion，在当前问题数据中，该编码出现的次数
6. representative_quotes, 该编码的典型引文

二、核心概念

本次优化的核心是进行一次彻底的"自下而上"（Bottom-up）的编码重构。我们将把原始编码本中的code name, definition, source_question, representative_quotes等信息视为理解编码内在含义的"语境数据"。整个分析过程将致力于从编码本身的含义出发，探索其内在联系，并从中"浮现"出新的结构与主题，而非依赖或修正原始的theme分类。

结合这次的研究问题，在编码时将关注点聚焦在"创造性"上。包括且不限于创造性是如何形成的、构成创造性的要素、创造过程体验与结果体验、创造中的主要行为、游戏激发、支持或干扰创造性的因素等。

三、 指导原则 (Guiding Principles)

1. 语义互斥原则 (Semantic Mutual Exclusivity)：最终编码本中的每一个Code_Name都必须代表一个独立、独特的概念。
2. 信息全覆盖原则 (Exhaustiveness)：重构后的编码体系必须全面覆盖原始编码所揭示的所有现象。
2.1. 低频处理：对于frequency_in_qestion < 3 的低频编码，将优先尝试将其意义融入到更宏观的父级编码的定义与规则中。
2.2. 无法归类处理：若低频编码的意义确实独特且无法融入其他编码，将统一归入一个名为"其他"的编码之下，并加以说明。
3. 同一个旧编码可以被重复使用，鉴于语义的丰富性，在建立新编码时要扫描整个的编码本，即使某个旧编码被使用过，只要能在某些方面反应当前新编码的含义，也可以再次合并。
4. 操作明确原则 (Operational Clarity)：每一个编码都必须配备详尽的Application_Rules（应用规则），包含清晰的"纳入标准"和"排除标准"，确保编码的可执行性和一致性。

四、引导过程

步骤一、宏观理解。对LLM的首次分析要记录。
以下是这个inductive coding的到的编码本。我们称之为raw-codebook。请先阅读，然后说下，你在其中发现了哪些你觉得值得关注的信息：

步骤二、聚焦主题。结合LLM 分析结果，以及对raw codebook的预览，让LLM关注某一信息主题。此时，如果能提供一些理论模型让LLM作为模版，效果更好。
“成就感” 在多个编码中出现。你先扫描下整个raw codebook，收集哪些编码和“成就感”相关的。这可能涉及成就感的不同的方面...[适当引导]...围绕这个主题先做一次编码。编码时以问题、引文和原始的theme作为语境来理解各编码的定义。

步骤三、深入挖掘或矫正方向。
1. 深入挖掘。LLM给出的结果与研究者对raw codebook的预览一致时，可深度探索已被识别出的主题下更有意义和更精确的主题。
2. 矫正方向。LLM 给出的结果与研究者对raw codebook的预览产生偏差时，需要引导LLM重新执行第二步骤。

步骤四、确认结果。让LLM根据当前编码用以下格式建立一个初步编码本。
我们将建立新的编码本，命名为new-codebok, 以便和旧编码本 raw-codebok 区分开。请将我们目前的分析结果放入new-codebook中，并打印出来，用表格形式，显示以下信息：

| 列名称 (Column Name)	| 说明 (Description)| 
| Theme	| 二次提取出的、全新的、高度抽象的概念性主题。| 
| Code_Name	| 提炼出的、4个字以内的新编码名称。| 
| Merged_Original_Codes	|  一个文本字符串List，[原编码1,原编码2，...]，列出了所有被合并成此新编码的原始编码名称。| 
| Total_Original_Frequency	| 一个整数，代表所有被合并的原始编码的频数（frequency_in_qestion）之和。| 
| Definition	| 对新编码核心概念的全面、精确的文字定义。| 
| Application_Rules	| 详细的编码应用指南，包含清晰的纳入和排除标准。| 

步骤五、下一个主题。基本模式是重复步骤二、三、四。需要强调对所有编码的复用。
非常好，我们现在焦距在“与社交相关”的编码，请你搜索整个编码本，看看有哪些编码与“社交”相关，以及从哪些方面相关、为何相关。注意，即使之前已经被用过的编码仍然需要识别。每个旧编码可能包含多层含义。

步骤六、当核心关键信息提取出来后，要求对编码本进行第一次优化，包括合并相似编码，补充编码元素等。

步骤七、完善编码。让LLM对全文搜索，找出尚未被编码的
请你对照raw-codebook和new-codebook，列出我们尚未在new-codebook中包含的编码。
*** ***

四、 执行流程 (Execution Workflow)

我将严格按照以下四个步骤执行重构工作：

步骤一：编码理解与聚类 (Code Understanding and Affinity Grouping)

1. 动作：我将逐一读取原始编码本中的每一行。对每一个编码，请综合其definition、source_question和representative_quotes来精确理解其内在含义。
2. 产出：基于理解，对所有编码进行"亲和度分组"，将语义上指向同一或相似核心概念的原始编码聚合在一起，形成多个"编码簇"（Code Clusters）。

步骤二：新编码提炼与规则撰写 (New Code Refinement and Rule Formulation)

1. 动作：针对上一步形成的每一个"编码簇"，按照以下规则操作：
1.1. 提炼并创造一个概括级别更高、信息粒度适中的新编码。
1.2. 确保新的Code_Name长度在4个中文字以内。
1.3. 为新编码撰写精准的Definition。
1.4. 为新编码制定详细的Application_Rules。
1.5. 使用中文。
2. 产出：一个由经过提炼的新编码构成的列表，每个编码都附带了定义和使用规则。

步骤三：二次主题提取 (Second-Order Theme Extraction)

1. 动作：在所有新编码生成之后，我将完全忽略原始的theme信息。我会分析步骤二产出的所有新编码的内在逻辑关系和概念范畴，进行第二轮的归纳与抽象。
2. 产出：全新的、能清晰概括其下属新编码的、更具抽象概念性的Theme（主题）。

步骤四：整合与终审 (Integration and Final Review)

1. 动作：我将把前序步骤的产出整合成最终的编码本。并对照所有指导原则，进行最终审核，确保逻辑的严密性和操作的清晰性。
2. 产出：最终的CSV格式演绎编码本。

五、最终输出格式 (Final Output Format)

输出的CSV文件将严格遵循我们商定的格式，包含四列：

| 列名称 (Column Name)	| 说明 (Description)| 
| Theme	| 二次提取出的、全新的、高度抽象的概念性主题。| 
| Code_Name	| 提炼出的、4个字以内的新编码名称。| 
| Merged_Original_Codes	|  一个文本字符串List，[原编码1,原编码2，...]，列出了所有被合并成此新编码的原始编码名称。| 
| Total_Original_Frequency	| 一个整数，代表所有被合并的原始编码的频数（frequency_in_qestion）之和。| 
| Definition	| 对新编码核心概念的全面、精确的文字定义。| 
| Application_Rules	| 详细的编码应用指南，包含清晰的纳入和排除标准。| 


# 人机合作模式

人机协同质性分析工作手册 (v4.0 - 最终版)

一、 核心哲学：研究者主导的迭代式意义建构
本手册描述的并非一次性的任务处理，而是一套循环往复、螺旋上升的协同研究流程。其核心在于，承认任何由AI辅助生成的编码本都只是一个“高质量的草案”，它必须经过研究者基于其深厚“认知基础”（理论学识、田野经验、研究直觉）的反复验证和修正，直至该编码本的信息粒度、饱和度、全面性与独立性等指标，达到研究者认可的“认知阈值”。

二、 角色分工：总设计师与研究助理
我们成功的基石，是明确且不可逾越的角色分工：

研究者 (您) - 总设计师与最终决策者

战略导航: 设定研究目标，定义探索的“关注点”。
智慧核心: 注入理论视角，进行深度的意义诠释与概念建构。
质量守门: 执行关键的“验证”步骤，对编码本的完备性和准确性进行审计，并做出最终裁决。
节奏掌控: 作为项目的管理者，决定何时推进、何时深化、何时存档。
AI (我) - 研究助理与认知增强工具

超级检索引擎: 按指令对原始数据进行快速、全面地语义扫描与检索。
信息处理器: 对信息进行初步的结构化分类与归纳。
灵感催化剂: 提供多维度的视角、诠释的可能性，或作为“思考的墙壁”供您碰撞想法。
高效文书: 负责将您的决策精准地、结构化地生成为文档，并处理所有溯源信息的记录。

三、 宏观工作流：探索-建构-验证的循环
我们的合作遵循一个三阶段的宏观循环。

阶段一：探索循环 (The Exploration Loop): 围绕特定焦点，从原始数据中“浮现”出核心概念。
阶段二：整合与生成 (Integration & Generation): 在探索完所有主要焦点后，AI根据指令，将所有阶段性成果整合成一个统一的、结构化的**“编码本草案”**。
阶段三：验证与修正 (The Validation & Refinement Loop): 研究者对“草案”进行审计，发现缺环，并启动新一轮的“探索循环”来弥补和完善。
四、 合作节奏与过程管理
这是确保长期、复杂合作顺利进行的核心管理策略。

阶段性提示语系统设计 (Phased Prompting System):

探索阶段: 提示语应是开放式的，旨在最大化地检索信息。例如：“请找出所有与‘社交’相关的编码。”
建构阶段: 提示语应是指令式的，旨在将研究者的思考结构化。例如：“请将A、B、C三个编码合并为‘趣味互动’，并撰写定义和规则。”
验证阶段: 提示语应是批判性的，旨在挑战和检验草案的完备性。例如：“恶作互动频数很高但未被纳入，请以此为核心，重新审视社交维度。”
演进的规范与输出格式 (Evolving Standards & Outputs):

合作初期，对AI的输出要求可以较为简单（如仅列出编码名称）。
随着理解的深入，逐步提高输出规范的复杂度，要求包含定义、规则，乃至我们最终的6列溯源信息。这个“逐步求精”的过程，本身就是研究深化的体现。
迭代式存档与版本控制 (Iterative Archiving & Versioning):

在每个关键节点（如完成所有焦点的初步探索后，或完成一次重要的验证与修正后），研究者应明确要求AI生成一份带有版本号的、完整的阶段性成果（如我们的 v5.0, v6.0 编码本）。
目的:
创建检查点: 固化成果，防止在后续探索中丢失有价值的中间版本。
清晰化进程: 使合作的脉络和进展一目了然。
可追溯性: 为最终的研究报告提供清晰、可审计的过程性材料。
五、 合作成功的关键原则
研究者绝对主导: AI始终是辅助工具，研究者的智慧和判断是研究质量的唯一保证。
拥抱“不完美”的草案: 将AI的每次输出都视为一个待您批判和完善的“脚手架”，而不是终点。
对话优于指令: 将与AI的互动视为一场持续的对话，通过反复追问和澄清来逼近真相。
对错误的开放性: 坦诚面对并修正过程中出现的错误，是建立信任和通往正确结果的最快路径。